{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396d6cd0-7fa2-4eeb-bef0-bbb5a568d4a1",
   "metadata": {},
   "source": [
    "### Exercise: Monte Carlo Pi on the GPU\n",
    "\n",
    "Let's revisit Monte Carlo Pi generating algorithm from the first section, where we had compiled it with Numba on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b73adea-c5a9-414a-aed8-d9d0aba175bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "from numba.cuda.random import xoroshiro128p_uniform_float32\n",
    "import math\n",
    "\n",
    "threads_per_block = 64\n",
    "blocks = 24\n",
    "rng_states = create_xoroshiro128p_states(threads_per_block * blocks, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ad9c2e8-3077-412f-96da-a0fe4e05276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "import random\n",
    "\n",
    "@njit\n",
    "def monte_carlo_pi(nsamples):\n",
    "    acc = 0\n",
    "    for i in range(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if (x**2 + y**2) < 1.0:\n",
    "            acc += 1\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "887ba112-d940-4991-a7c3-947a3c3b2d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492 ms ± 9.69 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "nsamples = 10000000\n",
    "%timeit monte_carlo_pi(nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf3665d-7a75-4333-987b-fdfd48526b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "import random\n",
    "\n",
    "# TODO: All your work will be in this cell. Refactor to run on the device successfully given the way the\n",
    "# kernel is launched below.\n",
    "@cuda.jit\n",
    "def monte_carlo_pi_device(rng_states, samples, out):\n",
    "    # Obtener el índice global único para este hilo\n",
    "    # idx = cuda.grid(1) podría ser más idiomático aquí\n",
    "    thread_id = cuda.grid(1) # Equivalente a cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "\n",
    "    # Asegurarse de no exceder los límites del array rng_states o out\n",
    "    # (Buena práctica, aunque en este caso grid_size coincide)\n",
    "    if thread_id >= rng_states.shape[0]:\n",
    "        return\n",
    "        \n",
    "    acc = 0\n",
    "    for i in range(samples): # Usar el argumento 'samples' (samples_per_thread)\n",
    "        # Generar números aleatorios usando el estado del hilo actual\n",
    "        x = xoroshiro128p_uniform_float32(rng_states, thread_id)\n",
    "        y = xoroshiro128p_uniform_float32(rng_states, thread_id)\n",
    "\n",
    "        # Verificar si el punto está dentro del círculo unitario\n",
    "        if x**2 + y**2 < 1.0:\n",
    "            acc += 1\n",
    "\n",
    "    # Escribir la proporción calculada por este hilo en el array de salida\n",
    "    # Cada hilo calcula su propia estimación parcial de Pi / 4\n",
    "    out[thread_id] = 4.0 * acc / samples # Escribir en el array 'out', NO retornar\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "804063ff-7c18-47ac-a2f3-3cceaa70282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change any of the values in this cell\n",
    "nsamples = 10000000\n",
    "threads_per_block = 128\n",
    "blocks = 32\n",
    "\n",
    "grid_size = threads_per_block * blocks\n",
    "samples_per_thread = int(nsamples / grid_size) # Each thread only needs to work on a fraction of total number of samples.\n",
    "                                               # This could also be calcuated inside the kernel definition using `gridsize(1)`.\n",
    "\n",
    "rng_states = create_xoroshiro128p_states(grid_size, seed=1)\n",
    "d_out = cuda.device_array(threads_per_block * blocks, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "490cb951-11ad-4898-ac3d-8869b3118317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\miniconda3\\envs\\env_numba\\lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ms ± 152 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit monte_carlo_pi_device[blocks, threads_per_block](rng_states, samples_per_thread, d_out); cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41dc4d06-8811-4129-9f75-978944a46fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1413999\n"
     ]
    }
   ],
   "source": [
    "# Celda después de llamar al kernel y sincronizar:\n",
    "print(d_out.copy_to_host().mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Numba Only)",
   "language": "python",
   "name": "env_numba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
